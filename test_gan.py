"""
GANæ¨¡å‹å¢å¼ºæµ‹è¯•è„šæœ¬
åŠŸèƒ½ï¼š
1. ä½¿ç”¨å®Œæ•´å¥å­ä½œä¸ºæ–‡ä»¶åï¼ˆç©ºæ ¼æ›¿æ¢ä¸ºä¸‹åˆ’çº¿ï¼‰
2. å½©è‰²éª¨æ¶æ¸²æŸ“ï¼ˆå¤´éƒ¨çº¢è‰²ï¼Œæ‰‹è‡‚ç»¿è‰²ï¼Œé¢ˆéƒ¨è“è‰²ï¼‰
3. æ”¯æŒéšæœºå™ªå£°ç”Ÿæˆå¤šæ ·åŒ–åŠ¨ä½œ
ä½¿ç”¨æ–¹æ³•: python test_gan_enhanced.py
"""

import numpy as np
import torch
import scipy.io as scio
from model.gan_structure import GANModel
from utils.my_functions import load_w2v
from model.visualization_original import visualize_action_complete
import os


class GANTester:
    """
    GANæµ‹è¯•å™¨ - ç”¨äºåŠ è½½è®­ç»ƒå¥½çš„GANæ¨¡å‹å¹¶ç”ŸæˆåŠ¨ä½œåºåˆ—
    """

    def __init__(self, model, init_pose, model_path,
                 sentence_steps, action_steps, dim_sentence,
                 dim_char_enc, dim_gen, dim_random, dim_action=263,
                 device='cuda', use_random_noise=False):
        self.device = torch.device(device if torch.cuda.is_available() else 'cpu')

        self.model = model.to(self.device)
        self.action_steps = action_steps
        self.dim_action = dim_action  # æ”¯æŒå¯é…ç½®çš„åŠ¨ä½œç»´åº¦ï¼Œé»˜è®¤263ï¼ˆHumanML3Dæ ‡å‡†ç‰ˆï¼‰
        self.num_data = 1  # æµ‹è¯•æ—¶batch_size=1

        self.init_pose = init_pose
        self.batch_init = np.transpose(np.tile(self.init_pose, (1, self.num_data)), [1, 0])

        self.model_path = model_path
        self.sentence_steps = sentence_steps
        self.dim_sentence = dim_sentence
        self.dim_char_enc = dim_char_enc
        self.dim_gen = dim_gen
        self.dim_random = dim_random
        self.use_random_noise = use_random_noise

        # åŠ è½½è®­ç»ƒå¥½çš„æ¨¡å‹
        self._load_model()

    def _load_model(self):
        """åŠ è½½è®­ç»ƒå¥½çš„GANæ¨¡å‹æƒé‡"""
        print(f"Loading GAN model from {self.model_path}...")
        checkpoint = torch.load(self.model_path, map_location=self.device)
        self.model.load_state_dict(checkpoint['model_state_dict'])
        self.model.eval()  # è®¾ç½®ä¸ºè¯„ä¼°æ¨¡å¼
        print(f"GAN model loaded successfully! (Epoch: {checkpoint.get('epoch', 'unknown')})")

    def test(self, test_script, test_script_len):
        """
        æµ‹è¯•å‡½æ•° - ä»æ–‡æœ¬ç”ŸæˆåŠ¨ä½œåºåˆ—

        Args:
            test_script: [1, dim_sentence, sentence_steps] è¾“å…¥æ–‡æœ¬embedding
            test_script_len: [1] æ–‡æœ¬é•¿åº¦

        Returns:
            test_esti: [1, dim_action, action_steps] ç”Ÿæˆçš„åŠ¨ä½œåºåˆ—
        """
        with torch.no_grad():  # æµ‹è¯•æ—¶ä¸éœ€è¦æ¢¯åº¦
            # è½¬æ¢ä¸ºtorch tensor
            script_tensor = torch.FloatTensor(test_script).to(self.device)
            length_tensor = torch.LongTensor(test_script_len)

            # è½¬ç½®ä»¥åŒ¹é…æ¨¡å‹è¾“å…¥æ ¼å¼ [batch, sentence_steps, dim_sentence]
            script_batch = script_tensor.transpose(1, 2)

            # å‡†å¤‡åˆå§‹è¾“å…¥
            curr_init_input = torch.FloatTensor(self.batch_init).to(self.device)

            # æ ¹æ®é…ç½®é€‰æ‹©ä½¿ç”¨éšæœºå™ªå£°æˆ–é›¶å™ªå£°
            if self.use_random_noise:
                # GANè®­ç»ƒæ—¶ä½¿ç”¨éšæœºå™ªå£°ï¼Œå¯ä»¥ç”Ÿæˆå¤šæ ·åŒ–çš„åŠ¨ä½œ
                curr_random = torch.randn(self.num_data, self.sentence_steps,
                                          self.dim_random).to(self.device)
                print("  ä½¿ç”¨éšæœºå™ªå£°ç”Ÿæˆï¼ˆå¤šæ ·åŒ–è¾“å‡ºï¼‰")
            else:
                # ä½¿ç”¨é›¶å™ªå£°ï¼Œç”Ÿæˆç¡®å®šæ€§çš„ç»“æœ
                curr_random = torch.zeros(self.num_data, self.sentence_steps,
                                          self.dim_random).to(self.device)
                print("  ä½¿ç”¨é›¶å™ªå£°ç”Ÿæˆï¼ˆç¡®å®šæ€§è¾“å‡ºï¼‰")

            # 1. ç¼–ç æ–‡æœ¬
            char_enc_out = self.model.char_encoder(script_batch, length_tensor)

            # 2. ä»æ–‡æœ¬ç”ŸæˆåŠ¨ä½œï¼ˆä½¿ç”¨GANçš„generatorï¼‰
            action_gen_list = self.model.char2action(
                char_enc_out, curr_init_input, curr_random, self.num_data
            )

            # å°†listè½¬æ¢ä¸ºtensor [batch, action_steps, dim_action]
            action_gen_out = torch.stack(action_gen_list, dim=1)

            # è½¬æ¢å›numpyå¹¶è½¬ç½®ä¸º [1, dim_action, action_steps]
            test_esti = action_gen_out.cpu().numpy().transpose(0, 2, 1)

        return test_esti


def test_with_enhanced_visualization(tester, w2v_model, sentence, output_dir='./test_results'):
    """
    ä½¿ç”¨å¢å¼ºå¯è§†åŒ–æµ‹è¯•GANæ¨¡å‹

    Args:
        tester: GANTesterå¯¹è±¡
        w2v_model: Word2Vecæ¨¡å‹
        sentence: æµ‹è¯•å¥å­
        output_dir: è¾“å‡ºç›®å½•
    """
    print(f"\n{'='*70}")
    print(f"æµ‹è¯•å¥å­: '{sentence}'")
    print(f"{'='*70}")

    # 1. è½¬æ¢å¥å­ä¸ºembedding
    print("\n[1/4] ç¼–ç å¥å­...")
    words = sentence.lower().split()
    test_script = np.zeros((1, 300, 30))

    found_words = 0
    for i, word in enumerate(words[:30]):
        if word in w2v_model:
            test_script[0, :, i] = w2v_model[word]
            print(f"  âœ“ '{word}'")
            found_words += 1
        else:
            print(f"  âš ï¸  '{word}' (ä¸åœ¨è¯æ±‡è¡¨ä¸­ï¼Œä½¿ç”¨é›¶å‘é‡)")

    test_script_len = np.array([min(len(words), 30)])
    print(f"  ç¼–ç å®Œæˆ: {found_words}/{len(words)} ä¸ªè¯åœ¨è¯æ±‡è¡¨ä¸­")

    # 2. ç”ŸæˆåŠ¨ä½œ
    print(f"\n[2/4] ç”ŸæˆåŠ¨ä½œåºåˆ—...")
    generated_action = tester.test(test_script, test_script_len)

    print(f"  âœ“ åŠ¨ä½œå½¢çŠ¶: {generated_action.shape}")
    print(f"  âœ“ å‡å€¼: {generated_action.mean():.4f}")
    print(f"  âœ“ æ ‡å‡†å·®: {generated_action.std():.4f}")
    print(f"  âœ“ èŒƒå›´: [{generated_action.min():.4f}, {generated_action.max():.4f}]")

    # 3. ä¿å­˜.npyæ–‡ä»¶ï¼ˆä½¿ç”¨å®Œæ•´å¥å­åï¼‰
    print(f"\n[3/4] ä¿å­˜åŠ¨ä½œæ•°æ®...")
    os.makedirs(output_dir, exist_ok=True)

    # ä½¿ç”¨å®Œæ•´å¥å­ï¼Œæ›¿æ¢ç©ºæ ¼ä¸ºä¸‹åˆ’çº¿
    filename_prefix = sentence.lower().replace(' ', '_')
    npy_path = os.path.join(output_dir, f'{filename_prefix}_action.npy')

    np.save(npy_path, generated_action)
    print(f"  âœ“ åŠ¨ä½œæ•°æ®ä¿å­˜åˆ°: {npy_path}")

    # 4. ç”Ÿæˆæ‰€æœ‰å¯è§†åŒ–ï¼ˆå½©è‰²ç‰ˆï¼‰
    print(f"\n[4/4] ç”Ÿæˆå½©è‰²å¯è§†åŒ–...")
    files = visualize_action_complete(generated_action, sentence, output_dir)

    return generated_action, files


def main():
    """ä¸»å‡½æ•°"""
    print("="*70)
    print("GANæ¨¡å‹æµ‹è¯• - å®Œæ•´æ–‡ä»¶å + å½©è‰²éª¨æ¶")
    print("="*70)
    print("\nç‰¹æ€§:")
    print("  âœ¨ æ–‡ä»¶åä½¿ç”¨å®Œæ•´å¥å­ï¼ˆç”¨ä¸‹åˆ’çº¿è¿æ¥ï¼‰")
    print("  ğŸ¨ å¤´éƒ¨å…³é”®ç‚¹: çº¢è‰²")
    print("  ğŸ¨ æ‰‹è‡‚/æ‰‹éƒ¨å…³é”®ç‚¹: ç»¿è‰²")
    print("  ğŸ¨ é¢ˆéƒ¨å…³é”®ç‚¹: è“è‰²")
    print("  ğŸ² å¯é€‰: ä½¿ç”¨éšæœºå™ªå£°ç”Ÿæˆå¤šæ ·åŒ–åŠ¨ä½œ")

    # ==================== é…ç½® ====================
    device = 'cuda' if torch.cuda.is_available() else 'cpu'
    print(f"\nä½¿ç”¨è®¾å¤‡: {device}")

    # æ¨¡å‹å‚æ•°
    sentence_steps = 30
    action_steps = 32
    dim_sentence = 300
    dim_char_enc = 300
    dim_gen = 300
    dim_dis = 300
    dim_action = 263  # HumanML3Dæ ‡å‡†ç‰ˆç»´åº¦
    dim_random = 10

    # è·¯å¾„
    model_path = './gan_model/model_epoch_345.pth'  # GANæ¨¡å‹è·¯å¾„
    mean_pose_path = './data/mean_pose.mat'
    w2v_path = './data/GoogleNews-vectors-negative300.bin'
    output_dir = './test_results'

    # æµ‹è¯•é…ç½®
    use_random_noise = False  # è®¾ä¸ºTrueå¯ä»¥ç”Ÿæˆå¤šæ ·åŒ–çš„åŠ¨ä½œ

    # ==================== æ£€æŸ¥æ–‡ä»¶ ====================
    print("\næ£€æŸ¥å¿…è¦æ–‡ä»¶...")
    required_files = [
        (model_path, "è®­ç»ƒå¥½çš„GANæ¨¡å‹"),
        (mean_pose_path, "å¹³å‡pose"),
        (w2v_path, "Word2Vecæ¨¡å‹")
    ]

    for file_path, description in required_files:
        if os.path.exists(file_path):
            print(f"  âœ“ {description}: {file_path}")
        else:
            print(f"  âœ— {description}æœªæ‰¾åˆ°: {file_path}")
            print(f"\nè¯·ç¡®ä¿ä»¥ä¸‹æ–‡ä»¶å­˜åœ¨:")
            print(f"  - {model_path}")
            print(f"  - {mean_pose_path}")
            print(f"  - {w2v_path}")
            return

    # ==================== åŠ è½½æ¨¡å‹ ====================
    print("\n" + "="*70)
    print("åŠ è½½GANæ¨¡å‹å’ŒWord2Vec")
    print("="*70)

    print("\nåˆ›å»ºGANæ¨¡å‹ç»“æ„...")
    model = GANModel(
        sentence_steps=sentence_steps,
        action_steps=action_steps,
        dim_sentence=dim_sentence,
        dim_char_enc=dim_char_enc,
        dim_gen=dim_gen,
        dim_dis=dim_dis,
        dim_action=dim_action,
        dim_random=dim_random
    )

    print("åŠ è½½åˆå§‹pose...")
    init_pose = scio.loadmat(mean_pose_path)['mean_vector']

    print("åˆ›å»ºGANæµ‹è¯•å™¨...")
    tester = GANTester(
        model=model,
        init_pose=init_pose,
        model_path=model_path,
        sentence_steps=sentence_steps,
        action_steps=action_steps,
        dim_sentence=dim_sentence,
        dim_char_enc=dim_char_enc,
        dim_gen=dim_gen,
        dim_random=dim_random,
        dim_action=dim_action,
        device=device,
        use_random_noise=use_random_noise
    )

    print("åŠ è½½Word2Vecæ¨¡å‹...")
    w2v_model = load_w2v(w2v_path)

    # ==================== æµ‹è¯•å¥å­ ====================
    print("\n" + "="*70)
    print("å¼€å§‹æµ‹è¯•")
    print("="*70)

    # å®šä¹‰æµ‹è¯•å¥å­ï¼ˆå¯ä»¥æ˜¯æ›´é•¿çš„æè¿°ï¼‰
    test_sentences = [
        "a man is pointing at a tree",
        "a woman is dancing",
        "a man is lifting weights",
        "a person is waving hands",
        "someone is throwing a ball",
        "a girl is jumping",
        "a man playing drums"
    ]

    print(f"\nå°†æµ‹è¯• {len(test_sentences)} ä¸ªå¥å­")
    print("\næ¯ä¸ªå¥å­å°†ç”Ÿæˆ 4 ä¸ªæ–‡ä»¶:")
    print("  1. [å®Œæ•´å¥å­]_8frames.png        - 8ä¸ªå…³é”®å¸§ï¼ˆå½©è‰²ï¼‰")
    print("  2. [å®Œæ•´å¥å­]_animation.gif      - 32å¸§åŠ¨ç”»ï¼ˆå½©è‰²ï¼‰")
    print("  3. [å®Œæ•´å¥å­]_32frames_grid.png - 32å¸§ç½‘æ ¼å›¾ï¼ˆå½©è‰²ï¼‰")
    print("  4. [å®Œæ•´å¥å­]_action.npy        - åŠ¨ä½œæ•°æ®")

    if use_random_noise:
        print("\nâš ï¸  æ³¨æ„: ä½¿ç”¨éšæœºå™ªå£°æ¨¡å¼ï¼Œæ¯æ¬¡è¿è¡Œä¼šç”Ÿæˆä¸åŒçš„åŠ¨ä½œ!")
    else:
        print("\nâœ“ ä½¿ç”¨ç¡®å®šæ€§æ¨¡å¼ï¼Œæ¯æ¬¡è¿è¡Œç»“æœä¸€è‡´")

    print("\næ–‡ä»¶åç¤ºä¾‹:")
    for sent in test_sentences[:1]:
        example_name = sent.lower().replace(' ', '_')
        print(f"  '{sent}'")
        print(f"    â†’ {example_name}_8frames.png")
        print(f"    â†’ {example_name}_animation.gif")
        print(f"    â†’ {example_name}_32frames_grid.png")
        print(f"    â†’ {example_name}_action.npy")

    # æµ‹è¯•æ¯ä¸ªå¥å­
    all_results = {}
    for i, sentence in enumerate(test_sentences, 1):
        print(f"\n\n{'#'*70}")
        print(f"æµ‹è¯• {i}/{len(test_sentences)}")
        print(f"{'#'*70}")

        try:
            action, files = test_with_enhanced_visualization(
                tester, w2v_model, sentence, output_dir
            )
            all_results[sentence] = {'action': action, 'files': files}
        except Exception as e:
            print(f"\nâœ— æµ‹è¯•å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            continue

    # ==================== æ€»ç»“ ====================
    print("\n" + "="*70)
    print("æµ‹è¯•å®Œæˆï¼")
    print("="*70)

    print(f"\nâœ“ æˆåŠŸç”Ÿæˆ {len(all_results)} ä¸ªåŠ¨ä½œåºåˆ—")
    print(f"âœ“ ç»“æœä¿å­˜åœ¨: {output_dir}")

    print("\nç”Ÿæˆçš„æ–‡ä»¶:")
    total_files = 0
    for sentence, result in all_results.items():
        print(f"\n  '{sentence}':")
        for file_type, path in result['files'].items():
            if os.path.exists(path):
                size_kb = os.path.getsize(path) / 1024
                filename = os.path.basename(path)
                print(f"    âœ“ {filename} ({size_kb:.1f} KB)")
                total_files += 1
            else:
                print(f"    âœ— {file_type}: æœªç”Ÿæˆ")
        # æ˜¾ç¤º.npyæ–‡ä»¶
        npy_name = sentence.lower().replace(' ', '_') + '_action.npy'
        npy_path = os.path.join(output_dir, npy_name)
        if os.path.exists(npy_path):
            size_kb = os.path.getsize(npy_path) / 1024
            print(f"    âœ“ {npy_name} ({size_kb:.1f} KB)")
            total_files += 1

    print(f"\næ€»å…±ç”Ÿæˆ: {total_files} ä¸ªæ–‡ä»¶")

    print("\n" + "="*70)
    print("GANæ¨¡å‹ç‰¹æ€§è¯´æ˜")
    print("="*70)
    print("âœ¨ ç›¸æ¯”Seq2Seqæ¨¡å‹çš„ä¼˜åŠ¿:")
    print("   âœ“ é€šè¿‡å¯¹æŠ—è®­ç»ƒæé«˜åŠ¨ä½œè´¨é‡")
    print("   âœ“ ç”Ÿæˆçš„åŠ¨ä½œæ›´åŠ è‡ªç„¶å’Œå¤šæ ·åŒ–")
    print("   âœ“ æ”¯æŒéšæœºå™ªå£°ç”Ÿæˆä¸åŒå˜ä½“")
    print("\nğŸ² éšæœºå™ªå£°æ¨¡å¼:")
    print("   - è®¾ç½® use_random_noise=True å¯ä»¥ä¸ºåŒä¸€å¥å­ç”Ÿæˆå¤šä¸ªä¸åŒçš„åŠ¨ä½œ")
    print("   - é€‚åˆéœ€è¦åŠ¨ä½œå¤šæ ·æ€§çš„åº”ç”¨åœºæ™¯")
    print("   - å½“å‰è®¾ç½®: use_random_noise=" + str(use_random_noise))

    print("\n" + "="*70)
    print("é¢œè‰²ç¼–ç è¯´æ˜")
    print("="*70)
    print("ğŸ”´ çº¢è‰²: å¤´éƒ¨å…³é”®ç‚¹ (joint 7)")
    print("ğŸŸ¢ ç»¿è‰²: æ‰‹è‡‚å’Œæ‰‹éƒ¨å…³é”®ç‚¹ (joints 1-6)")
    print("ğŸ”µ è“è‰²: é¢ˆéƒ¨å…³é”®ç‚¹ (joint 0, åŸºå‡†ç‚¹)")
    print("\nä¼˜ç‚¹:")
    print("  âœ“ æ›´å®¹æ˜“è¯†åˆ«ä¸åŒèº«ä½“éƒ¨ä½")
    print("  âœ“ è§†è§‰ä¸Šæ›´ç›´è§‚")
    print("  âœ“ ä¾¿äºåˆ†æåŠ¨ä½œè´¨é‡")

    print("\n" + "="*70)
    print("ä½¿ç”¨å»ºè®®")
    print("="*70)
    print("1. æŸ¥çœ‹ *_8frames.png å¿«é€Ÿé¢„è§ˆåŠ¨ä½œ")
    print("2. æ’­æ”¾ *_animation.gif è§‚å¯Ÿæµç•…åº¦")
    print("3. æ£€æŸ¥ *_32frames_grid.png åˆ†æç»†èŠ‚")
    print("4. å¯¹æ¯”Seq2Seqå’ŒGANçš„ç»“æœ:")
    print("   - GANç”Ÿæˆçš„åŠ¨ä½œåº”è¯¥æ›´åŠ å¹³æ»‘")
    print("   - GANç”Ÿæˆçš„åŠ¨ä½œåº”è¯¥æ›´ç¬¦åˆç‰©ç†è§„å¾‹")
    print("   - GANç”Ÿæˆçš„åŠ¨ä½œåº”è¯¥æœ‰æ›´å¥½çš„è¯­ä¹‰å¯¹é½")
    print("\n5. å¦‚æœæƒ³ç”Ÿæˆå¤šä¸ªå˜ä½“:")
    print("   - è®¾ç½® use_random_noise=True")
    print("   - å¤šæ¬¡è¿è¡Œè„šæœ¬è·å¾—ä¸åŒç»“æœ")


if __name__ == "__main__":
    main()
